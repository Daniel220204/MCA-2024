# \[Enter your portfolio title here\]
\[Enter your responses to Week 1, tasks 2 and 3 here\]
Week1
Theme of my dataset-Kanye West《Moon》
3 types data
1.Sheet Music https://musescore.com/user/35581442/scores/6991389?share=copy_link
2.Metadata
•Key metadata for “Moon” includes:
 Song Title: Moon
 Artist: Kanye West
 Album: Donda (2021)
 Featuring Artists: Kid Cudi, Don Toliver
 Genre: Hip-Hop/Rap
 Track Length: 2:36
 Record Label: GOOD Music, Def Jam Recordings
3.Recording
 https://github.com/user-attachments/assets/f80dfa26-70a6-4000-b472-cf4e1a726e6e
 
The primary challenges in working with music data stem from restricted access, inconsistent curation, and fragmented distribution, all of which make it difficult to fully analyze and engage with music comprehensively.

Week 3
URL：https://Daniel220204.github.io/MCA-2024/verovio.html.
Test 2: A comparison of the elements of MusicXML and MEI reveals significant differences in the way they represent music data. Firstly, there is a difference in the representation of musical notes; MusicXML uses the <note> element with its sub-elements <pitch> and <duration> to provide richer semantic information, but MEI shows a more concise structure by using <pname> and <oct> in the <note> element. Secondly, for the representation of time signatures, MusicXML uses the <time> element and its sub-elements <beats> and <beat-type>, while MEI uses the <meterSig> element and its corresponding attributes, and although both convey the same information, the structure of MusicXML is a bit more flexible. Finally, for key signatures, MusicXML expresses them through the <key> element with its sub-elements <fifths> and <mode>, but MEI uses the <keySig> element to express the same. This difference results in MusicXML being better suited for reading, while MEI is better suited for quick parsing. Therefore, when choosing between using MusicXML and MEI, the choice of which to use should be based on the needs of the project.
